{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Advanced dMRI Feature Extraction** \n",
    "## CSD + Probabilistic Tractography + ROI-Based Tractometry with DIPY\n",
    "\n",
    "This pipeline implements a **reproducible, atlas-free framework** for extracting microstructural and geometric features from diffusion MRI data, suitable for:\n",
    "\n",
    "- Clinical biomarker discovery  \n",
    "- Machine learning in neurodegenerative disease  \n",
    "- Group-level white matter analysis  \n",
    "\n",
    "### Methods Summary\n",
    "- **Preprocessing**: Patch2Self denoising + Gibbs ringing removal  \n",
    "- **Reconstruction**: Constrained Spherical Deconvolution (CSD, `sh_order=6`)  \n",
    "- **Tractography**: Probabilistic Local Tracking with FA-based stopping  \n",
    "- **Bundle Extraction**: Anatomically informed ROIs in native space  \n",
    "- **Feature Extraction**: Along-tract profiles + geometric descriptors  \n",
    "\n",
    "### Data & Software\n",
    "- **Dataset**: Stanford HARDI (single-shell, *b* = 2000 s/mm¬≤, 150 diffusion directions)  \n",
    "- **Software**: DIPY v1.7+, Python 3.9+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports and setup complete.\n",
      "üìÅ Output directory: /mnt/movement/users/jaizor/xtra/notebooks/DWI/publication_dwi_features\n",
      "================================================================================\n",
      "STEP 1: DATA LOADING & QUALITY CONTROL\n",
      "================================================================================\n",
      "‚úì Data shape: (81, 106, 76, 160) (x, y, z, volumes)\n",
      "‚úì Voxel size: (2.0, 2.0, 2.0) mm\n",
      "‚úì b-values: [   0. 2000.] s/mm¬≤\n",
      "‚úì b=0 volumes: 10\n",
      "‚úì Diffusion volumes: 150\n",
      "\n",
      "üìä Signal Quality:\n",
      "  - Mean b=0 intensity: 330.9\n",
      "  - Mean DWI intensity: 55.7\n",
      "  - Estimated SNR: 1.61\n",
      "\n",
      "================================================================================\n",
      "STEP 2: PREPROCESSING\n",
      "================================================================================\n",
      "\n",
      "üîß Applying Patch2Self denoising...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Completed in 59.5s\n",
      "\n",
      "üîß Removing Gibbs ringing artifacts...\n",
      "  ‚úì Gibbs removal applied\n",
      "\n",
      "üß† Extracting brain mask...\n",
      "  ‚úì Brain voxels: 208,649 (32.0%)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: MICROSTRUCTURAL RECONSTRUCTION\n",
      "================================================================================\n",
      "üîß Fitting Diffusion Tensor Model...\n",
      "\n",
      "üìä White Matter Statistics (FA > 0.2):\n",
      "  FA:  0.395 ¬± 0.149\n",
      "  MD:  0.000616 mm¬≤/s\n",
      "\n",
      "üîß Estimating CSD response function...\n",
      "  ‚úì Response eigenvalues: [0.00128607 0.00029784 0.00029784]\n",
      "  ‚úì FA threshold ratio: 0.232\n",
      "\n",
      "üîß Fitting CSD model (sh_order=6)...\n",
      "\n",
      "üìä Generalized FA (GFA) in WM:\n",
      "  Mean: 0.831 ¬± 0.071\n",
      "\n",
      "================================================================================\n",
      "STEP 4: WHOLE-BRAIN TRACTOGRAPHY\n",
      "================================================================================\n",
      "üå± Generated 147,066 seeds in white matter\n",
      "\n",
      "üßµ Running probabilistic tractography...\n",
      "‚úì Generated 296,171 streamlines in 521.2s\n",
      "‚úì Retained 209,071 streamlines (20‚Äì200 mm)\n",
      "\n",
      "================================================================================\n",
      "STEP 5: ROI-BASED BUNDLE EXTRACTION\n",
      "================================================================================\n",
      "  ‚úì CC_ForcepsMajor: 23359 streamlines\n",
      "  ‚úì CC_ForcepsMinor: 18000 streamlines\n",
      "  ‚úì CST_L: 52631 streamlines\n",
      "  ‚úì CST_R: 54635 streamlines\n",
      "\n",
      "‚úÖ Successfully extracted 4 bundles\n",
      "\n",
      "================================================================================\n",
      "STEP 6: EXTRACTING ROBUST, CLINICALLY RELEVANT FEATURES\n",
      "================================================================================\n",
      "‚úÖ Saved 36 clinically meaningful features to: publication_dwi_features/dwi_features_clinical.csv\n",
      "\n",
      "üì¶ Included feature groups:\n",
      "  - Global: mean_FA, mean_MD, mean_GFA\n",
      "  - Per bundle (CC_ForcepsMajor, CC_ForcepsMinor, CST_L, CST_R):\n",
      "      ‚Ä¢ mean_FA, mean_MD, mean_GFA\n",
      "      ‚Ä¢ FA_asymmetry (anterior vs posterior)\n",
      "      ‚Ä¢ FA_Q1, FA_Q2, FA_Q3, FA_Q4 (profile along tract)\n",
      "\n",
      "================================================================================\n",
      "STEP 8: VISUALIZATION\n",
      "================================================================================\n",
      "‚úì Saved: microstructural_maps.png\n",
      "‚úì Saved: bundle_profiles.png\n",
      "\n",
      "‚úÖ All visualizations saved!\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETE: PUBLICATION-READY FEATURE EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "üìä Final Output:\n",
      "  - Subject: Stanford HARDI\n",
      "  - Streamlines: 209,071\n",
      "  - Bundles extracted: 4\n",
      "  - Total features: 36\n",
      "\n",
      "üìÅ Files generated:\n",
      "  - dwi_features.csv\n",
      "  - microstructural_maps.png\n",
      "  - bundle_profiles.png\n",
      "  - dwi_features_clinical.csv\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Imports & Setup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress DIPY deprecation warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Core libraries\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
    "from dipy.core.gradients import gradient_table\n",
    "import nibabel as nib\n",
    "\n",
    "# Preprocessing\n",
    "from dipy.denoise.patch2self import patch2self\n",
    "from dipy.denoise.gibbs import gibbs_removal\n",
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "# Reconstruction\n",
    "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
    "from dipy.reconst.dti import TensorModel, fractional_anisotropy, mean_diffusivity\n",
    "\n",
    "# Tractography\n",
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "from dipy.tracking.streamline import Streamlines, select_by_rois\n",
    "from dipy.tracking.utils import random_seeds_from_mask, length\n",
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "\n",
    "# Analysis\n",
    "from dipy.stats.analysis import afq_profile\n",
    "from dipy.data import get_sphere\n",
    "\n",
    "# Configuration\n",
    "OUTPUT_DIR = Path(\"./publication_dwi_features\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "plt.rcParams.update({\"font.size\": 10, \"font.family\": \"sans-serif\"})\n",
    "\n",
    "print(\"‚úÖ Imports and setup complete.\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "\n",
    "# üì• 1. Data Loading & Quality Control\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: DATA LOADING & QUALITY CONTROL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load Stanford HARDI dataset\n",
    "fetch_stanford_hardi()\n",
    "hardi_img, gtab = read_stanford_hardi()\n",
    "data = hardi_img.get_fdata()\n",
    "affine = hardi_img.affine\n",
    "voxel_size = hardi_img.header.get_zooms()[:3]\n",
    "\n",
    "# Validate acquisition parameters\n",
    "print(f\"‚úì Data shape: {data.shape} (x, y, z, volumes)\")\n",
    "print(f\"‚úì Voxel size: ({voxel_size[0]:.1f}, {voxel_size[1]:.1f}, {voxel_size[2]:.1f}) mm\")\n",
    "print(f\"‚úì b-values: {np.unique(gtab.bvals)} s/mm¬≤\")\n",
    "print(f\"‚úì b=0 volumes: {np.sum(gtab.b0s_mask)}\")\n",
    "print(f\"‚úì Diffusion volumes: {np.sum(~gtab.b0s_mask)}\")\n",
    "\n",
    "# Signal quality metrics\n",
    "b0_mean = np.mean(data[..., gtab.b0s_mask])\n",
    "dwi_mean = np.mean(data[..., ~gtab.b0s_mask])\n",
    "snr_estimate = b0_mean / np.std(data[data > 0])\n",
    "\n",
    "print(f\"\\nüìä Signal Quality:\")\n",
    "print(f\"  - Mean b=0 intensity: {b0_mean:.1f}\")\n",
    "print(f\"  - Mean DWI intensity: {dwi_mean:.1f}\")\n",
    "print(f\"  - Estimated SNR: {snr_estimate:.2f}\")\n",
    "\n",
    "\n",
    "# üßπ 2. Preprocessing\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: PREPROCESSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Patch2Self denoising\n",
    "start = time.time()\n",
    "print(\"\\nüîß Applying Patch2Self denoising...\")\n",
    "denoised_data = patch2self(data, gtab.bvals, model=\"ols\", verbose=False)\n",
    "print(f\"  ‚úì Completed in {time.time() - start:.1f}s\")\n",
    "\n",
    "# Gibbs ringing removal\n",
    "print(\"\\nüîß Removing Gibbs ringing artifacts...\")\n",
    "denoised_data = gibbs_removal(denoised_data, slice_axis=2)\n",
    "print(\"  ‚úì Gibbs removal applied\")\n",
    "\n",
    "# Brain extraction\n",
    "print(\"\\nüß† Extracting brain mask...\")\n",
    "b0_volumes = denoised_data[..., gtab.b0s_mask]\n",
    "_, brain_mask = median_otsu(\n",
    "    b0_volumes,\n",
    "    vol_idx=range(min(5, b0_volumes.shape[-1])),\n",
    "    median_radius=4,\n",
    "    numpass=4,\n",
    "    autocrop=False,\n",
    "    dilate=2,\n",
    ")\n",
    "masked_data = denoised_data * brain_mask[..., None]\n",
    "\n",
    "brain_voxels = np.sum(brain_mask)\n",
    "print(f\"  ‚úì Brain voxels: {brain_voxels:,} ({100 * brain_voxels / brain_mask.size:.1f}%)\")\n",
    "\n",
    "\n",
    "# üß¨ 3. Microstructural Reconstruction\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: MICROSTRUCTURAL RECONSTRUCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# DTI for FA-based stopping criterion\n",
    "print(\"üîß Fitting Diffusion Tensor Model...\")\n",
    "dti_model = TensorModel(gtab)\n",
    "dti_fit = dti_model.fit(masked_data, mask=brain_mask)\n",
    "FA = np.clip(np.nan_to_num(fractional_anisotropy(dti_fit.evals)), 0, 1)\n",
    "MD = np.nan_to_num(mean_diffusivity(dti_fit.evals))\n",
    "wm_mask = (FA > 0.2) & brain_mask\n",
    "\n",
    "print(f\"\\nüìä White Matter Statistics (FA > 0.2):\")\n",
    "print(f\"  FA:  {np.mean(FA[wm_mask]):.3f} ¬± {np.std(FA[wm_mask]):.3f}\")\n",
    "print(f\"  MD:  {np.mean(MD[wm_mask]):.6f} mm¬≤/s\")\n",
    "\n",
    "# CSD for fiber orientation estimation\n",
    "print(\"\\nüîß Estimating CSD response function...\")\n",
    "response, ratio = auto_response_ssst(gtab, masked_data, roi_radii=10, fa_thr=0.7)\n",
    "print(f\"  ‚úì Response eigenvalues: {response[0]}\")\n",
    "print(f\"  ‚úì FA threshold ratio: {ratio:.3f}\")\n",
    "\n",
    "print(\"\\nüîß Fitting CSD model (sh_order=6)...\")\n",
    "sphere = get_sphere(\"repulsion724\")\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order_max=6)\n",
    "csd_fit = csd_model.fit(masked_data, mask=brain_mask)\n",
    "GFA = np.nan_to_num(csd_fit.gfa)\n",
    "\n",
    "print(f\"\\nüìä Generalized FA (GFA) in WM:\")\n",
    "print(f\"  Mean: {np.mean(GFA[wm_mask]):.3f} ¬± {np.std(GFA[wm_mask]):.3f}\")\n",
    "\n",
    "\n",
    "# üéØ 4. Whole-Brain Tractography\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: WHOLE-BRAIN TRACTOGRAPHY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Probabilistic direction getter\n",
    "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(\n",
    "    csd_fit.shm_coeff,\n",
    "    max_angle=30.0,\n",
    "    sphere=sphere,\n",
    "    relative_peak_threshold=0.25,\n",
    ")\n",
    "\n",
    "# Seeding and tracking\n",
    "seeds = random_seeds_from_mask(wm_mask, affine=affine, seeds_count=2, seed_count_per_voxel=True)\n",
    "print(f\"üå± Generated {len(seeds):,} seeds in white matter\")\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(FA, threshold=0.15)\n",
    "print(\"\\nüßµ Running probabilistic tractography...\")\n",
    "start = time.time()\n",
    "streamlines = Streamlines(LocalTracking(\n",
    "    direction_getter=prob_dg,\n",
    "    stopping_criterion=stopping_criterion,\n",
    "    seeds=seeds,\n",
    "    affine=affine,\n",
    "    step_size=0.5,\n",
    "    maxlen=1000,\n",
    "    minlen=20,\n",
    "))\n",
    "print(f\"‚úì Generated {len(streamlines):,} streamlines in {time.time() - start:.1f}s\")\n",
    "\n",
    "# Length filtering\n",
    "lengths = np.array(list(length(streamlines)))\n",
    "valid = (lengths >= 20) & (lengths <= 200)\n",
    "streamlines = streamlines[valid]\n",
    "print(f\"‚úì Retained {len(streamlines):,} streamlines (20‚Äì200 mm)\")\n",
    "\n",
    "\n",
    "# üåê 5. ROI-Based Bundle Extraction\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: ROI-BASED BUNDLE EXTRACTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Anatomical ROI definitions (in voxel space)\n",
    "x_dim, y_dim, z_dim = data.shape[:3]\n",
    "mid_x, mid_y, mid_z = x_dim // 2, y_dim // 2, z_dim // 2\n",
    "\n",
    "bundle_rois = {\n",
    "    \"CC_ForcepsMajor\": (mid_x-3, mid_x+4, mid_y-15, mid_y, mid_z-5, mid_z+5),      # Posterior corpus callosum\n",
    "    \"CC_ForcepsMinor\": (mid_x-3, mid_x+4, mid_y+5, mid_y+20, mid_z-5, mid_z+5),     # Anterior corpus callosum\n",
    "    \"CST_L\": (mid_x+5, mid_x+15, mid_y-10, mid_y+10, mid_z-15, mid_z+15),          # Left corticospinal tract\n",
    "    \"CST_R\": (mid_x-15, mid_x-5, mid_y-10, mid_y+10, mid_z-15, mid_z+15),          # Right corticospinal tract\n",
    "}\n",
    "\n",
    "recognized_bundles = {}\n",
    "for name, (x1, x2, y1, y2, z1, z2) in bundle_rois.items():\n",
    "    roi = np.zeros_like(brain_mask)\n",
    "    roi[x1:x2, y1:y2, z1:z2] = 1\n",
    "    \n",
    "    selected = list(select_by_rois(\n",
    "        streamlines=streamlines,\n",
    "        rois=[roi],\n",
    "        affine=affine,\n",
    "        include=[True],\n",
    "        mode=\"any\"\n",
    "    ))\n",
    "    \n",
    "    if len(selected) > 10:\n",
    "        recognized_bundles[name] = Streamlines(selected)\n",
    "        print(f\"  ‚úì {name}: {len(selected)} streamlines\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è {name}: insufficient streamlines ({len(selected)})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully extracted {len(recognized_bundles)} bundles\")\n",
    "\n",
    "\n",
    "# üìä 6. Feature Extraction (Clinically Meaningful Only)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: EXTRACTING ROBUST, CLINICALLY RELEVANT FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define bundles of interest\n",
    "bundles_of_interest = {\n",
    "    \"CC_ForcepsMajor\": recognized_bundles.get(\"CC_ForcepsMajor\"),\n",
    "    \"CC_ForcepsMinor\": recognized_bundles.get(\"CC_ForcepsMinor\"),\n",
    "    \"CST_L\": recognized_bundles.get(\"CST_L\"),\n",
    "    \"CST_R\": recognized_bundles.get(\"CST_R\"),\n",
    "}\n",
    "\n",
    "# Global features (keep only microstructural)\n",
    "global_features = {\n",
    "    \"subject_id\": \"stanford_hardi_001\",\n",
    "    \"global_mean_FA\": float(np.mean(FA[wm_mask])),\n",
    "    \"global_mean_MD\": float(np.mean(MD[wm_mask])),\n",
    "    \"global_mean_GFA\": float(np.mean(GFA[wm_mask])),\n",
    "}\n",
    "\n",
    "# Bundle-specific features (only FA, MD, GFA, asymmetry, quartiles)\n",
    "for name, bundle in bundles_of_interest.items():\n",
    "    if bundle is None or len(bundle) < 10:\n",
    "        # If bundle missing, fill with NaNs\n",
    "        prefix = name\n",
    "        global_features[f\"{prefix}_mean_FA\"] = np.nan\n",
    "        global_features[f\"{prefix}_mean_MD\"] = np.nan\n",
    "        global_features[f\"{prefix}_mean_GFA\"] = np.nan\n",
    "        global_features[f\"{prefix}_FA_asymmetry\"] = np.nan\n",
    "        for q in range(1, 5):\n",
    "            global_features[f\"{prefix}_FA_Q{q}\"] = np.nan\n",
    "        continue\n",
    "\n",
    "    clean_sl = Streamlines([s for s in bundle if len(s) >= 10])\n",
    "    if len(clean_sl) < 10:\n",
    "        continue\n",
    "\n",
    "    # Sample FA/MD/GFA along streamlines\n",
    "    profiles = {}\n",
    "    for metric_name, metric_map in {\"FA\": FA, \"MD\": MD, \"GFA\": GFA}.items():\n",
    "        try:\n",
    "            profile = afq_profile(metric_map, clean_sl, affine=affine, n_points=100)\n",
    "            profiles[metric_name] = profile\n",
    "        except:\n",
    "            profiles[metric_name] = np.full(100, np.nan)\n",
    "\n",
    "    # Compute features\n",
    "    prefix = name\n",
    "    global_features[f\"{prefix}_mean_FA\"] = float(np.nanmean(profiles[\"FA\"]))\n",
    "    global_features[f\"{prefix}_mean_MD\"] = float(np.nanmean(profiles[\"MD\"]))\n",
    "    global_features[f\"{prefix}_mean_GFA\"] = float(np.nanmean(profiles[\"GFA\"]))\n",
    "\n",
    "    # FA asymmetry: (anterior - posterior) / (anterior + posterior)\n",
    "    fa_profile = profiles[\"FA\"]\n",
    "    anterior = np.nanmean(fa_profile[:25])   # Q1 = start (cortical end)\n",
    "    posterior = np.nanmean(fa_profile[75:])  # Q4 = end (deep or opposite side)\n",
    "    asym = (anterior - posterior) / (anterior + posterior + 1e-10)\n",
    "    global_features[f\"{prefix}_FA_asymmetry\"] = float(asym)\n",
    "\n",
    "    # FA quartiles (Q1 = start, Q4 = end)\n",
    "    for i in range(4):\n",
    "        q_mean = np.nanmean(fa_profile[25*i : 25*(i+1)])\n",
    "        global_features[f\"{prefix}_FA_Q{i+1}\"] = float(q_mean)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_final = pd.DataFrame([global_features])\n",
    "\n",
    "\n",
    "# üíæ 7. Save Features Set\n",
    "\n",
    "output_path = OUTPUT_DIR / \"dwi_features_clinical.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "n_features = df_final.shape[1]\n",
    "print(f\"‚úÖ Saved {n_features} clinically meaningful features to: {output_path}\")\n",
    "print(\"\\nüì¶ Included feature groups:\")\n",
    "print(\"  - Global: mean_FA, mean_MD, mean_GFA\")\n",
    "print(\"  - Per bundle (CC_ForcepsMajor, CC_ForcepsMinor, CST_L, CST_R):\")\n",
    "print(\"      ‚Ä¢ mean_FA, mean_MD, mean_GFA\")\n",
    "print(\"      ‚Ä¢ FA_asymmetry (anterior vs posterior)\")\n",
    "print(\"      ‚Ä¢ FA_Q1, FA_Q2, FA_Q3, FA_Q4 (profile along tract)\")\n",
    "\n",
    "\n",
    "# üìà 8. Visualization\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 8: VISUALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Microstructural maps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "mid_z = data.shape[2] // 2\n",
    "plots = [\n",
    "    (FA, \"Fractional Anisotropy\", \"hot\", 0, 1),\n",
    "    (MD, \"Mean Diffusivity (mm¬≤/s)\", \"viridis\", 0, 0.002),\n",
    "    (GFA, \"Generalized FA\", \"plasma\", 0, 0.6),\n",
    "    (np.nan_to_num(dti_fit.rd), \"Radial Diffusivity (mm¬≤/s)\", \"cividis\", 0, 0.002),\n",
    "]\n",
    "\n",
    "for ax, (data_map, title, cmap, vmin, vmax) in zip(axes.flat, plots):\n",
    "    im = ax.imshow(data_map[:, :, mid_z].T, cmap=cmap, origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title, fontweight=\"bold\", fontsize=11)\n",
    "    ax.axis(\"off\")\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.04, pad=0.04)\n",
    "    if \"mm¬≤/s\" in title:\n",
    "        cbar.ax.set_ylabel(\"√ó10‚Åª¬≥\", rotation=0, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"microstructural_maps.png\", dpi=200, bbox_inches=\"tight\")\n",
    "print(\"‚úì Saved: microstructural_maps.png\")\n",
    "\n",
    "# Bundle profiles ‚Äî FIXED: use `recognized_bundles` instead of `all_features`\n",
    "n_bundles = len(recognized_bundles)\n",
    "if n_bundles > 0:\n",
    "    fig, axes = plt.subplots(1, min(n_bundles, 4), figsize=(4 * min(n_bundles, 4), 3))\n",
    "    if min(n_bundles, 4) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, (name, bundle) in zip(axes, list(recognized_bundles.items())[:4]):\n",
    "        clean = Streamlines([s for s in bundle if len(s) >= 10])\n",
    "        if clean:\n",
    "            try:\n",
    "                profile = afq_profile(FA, clean, affine=affine, n_points=100)\n",
    "                ax.plot(profile, \"b-\", linewidth=2, alpha=0.8)\n",
    "                ax.fill_between(range(100), profile, alpha=0.2, color=\"blue\")\n",
    "                ax.set_title(f\"{name}\", fontweight=\"bold\")\n",
    "                ax.set_ylabel(\"FA\")\n",
    "                ax.set_xlabel(\"Tract position (%)\")\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, \"Profile\\nunavailable\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"bundle_profiles.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    print(\"‚úì Saved: bundle_profiles.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No bundles to visualize.\")\n",
    "\n",
    "plt.close(\"all\")\n",
    "print(\"\\n‚úÖ All visualizations saved!\")\n",
    "\n",
    "\n",
    "# üìù Summary\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PIPELINE COMPLETE: PUBLICATION-READY FEATURE EXTRACTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìä Final Output:\")\n",
    "print(f\"  - Subject: Stanford HARDI\")\n",
    "print(f\"  - Streamlines: {len(streamlines):,}\")\n",
    "print(f\"  - Bundles extracted: {len(recognized_bundles)}\")\n",
    "print(f\"  - Total features: {df_final.shape[1]}\")\n",
    "print(f\"\\nüìÅ Files generated:\")\n",
    "for f in OUTPUT_DIR.iterdir():\n",
    "    if f.is_file():\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject_id',\n",
       " 'global_mean_FA',\n",
       " 'global_mean_MD',\n",
       " 'global_mean_GFA',\n",
       " 'CC_ForcepsMajor_mean_FA',\n",
       " 'CC_ForcepsMajor_mean_MD',\n",
       " 'CC_ForcepsMajor_mean_GFA',\n",
       " 'CC_ForcepsMajor_FA_asymmetry',\n",
       " 'CC_ForcepsMajor_FA_Q1',\n",
       " 'CC_ForcepsMajor_FA_Q2',\n",
       " 'CC_ForcepsMajor_FA_Q3',\n",
       " 'CC_ForcepsMajor_FA_Q4',\n",
       " 'CC_ForcepsMinor_mean_FA',\n",
       " 'CC_ForcepsMinor_mean_MD',\n",
       " 'CC_ForcepsMinor_mean_GFA',\n",
       " 'CC_ForcepsMinor_FA_asymmetry',\n",
       " 'CC_ForcepsMinor_FA_Q1',\n",
       " 'CC_ForcepsMinor_FA_Q2',\n",
       " 'CC_ForcepsMinor_FA_Q3',\n",
       " 'CC_ForcepsMinor_FA_Q4',\n",
       " 'CST_L_mean_FA',\n",
       " 'CST_L_mean_MD',\n",
       " 'CST_L_mean_GFA',\n",
       " 'CST_L_FA_asymmetry',\n",
       " 'CST_L_FA_Q1',\n",
       " 'CST_L_FA_Q2',\n",
       " 'CST_L_FA_Q3',\n",
       " 'CST_L_FA_Q4',\n",
       " 'CST_R_mean_FA',\n",
       " 'CST_R_mean_MD',\n",
       " 'CST_R_mean_GFA',\n",
       " 'CST_R_FA_asymmetry',\n",
       " 'CST_R_FA_Q1',\n",
       " 'CST_R_FA_Q2',\n",
       " 'CST_R_FA_Q3',\n",
       " 'CST_R_FA_Q4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_final.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
