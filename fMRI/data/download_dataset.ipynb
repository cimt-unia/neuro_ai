{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0b10c2",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "The developmental fMRI dataset available through Nilearn contains functional MRI (fMRI) data from over 150 children and adults who watched a short Pixar film titled Partly Cloudy during scanning. This dataset was originally collected by Rebecca Saxeâ€™s lab at MIT and is hosted on OpenNeuro.\n",
    "\n",
    "\n",
    "\n",
    "**Pixar film:** https://www.youtube.com/watch?v=Hb7yykqb85U\n",
    "\n",
    "**Dataset:** https://openneuro.org/datasets/ds000228/versions/1.0.0\n",
    "\n",
    "**Nilearn:** https://nilearn.github.io/dev/modules/generated/nilearn.datasets.fetch_development_fmri.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd6dce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_development_fmri</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/jaizor/xtra/data/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">development_fmri</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_development_fmri\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/jaizor/xtra/data/nilearn_data/\u001b[0m\u001b[95mdevelopment_fmri\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 155 subjects.\n",
      "Phenotypic columns: ['participant_id', 'Age', 'AgeGroup', 'Child_Adult', 'Gender', 'Handedness']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import NiftiMapsMasker \n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LOAD DEVELOPMENT FMRI DATASET\n",
    "# -------------------------------\n",
    "path_folder = '/home/jaizor/jaizor/xtra/data/nilearn_data'\n",
    "dataset = datasets.fetch_development_fmri(verbose=0,data_dir=path_folder)\n",
    "fmri_files = dataset.func          # List of 4D fMRI filenames (155 subjects)\n",
    "confound_files = dataset.confounds # List of confound files (155)\n",
    "pheno = pd.DataFrame(dataset.phenotypic)\n",
    "\n",
    "print(f\"Loaded {len(fmri_files)} subjects.\")\n",
    "print(\"Phenotypic columns:\", pheno.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2633e8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Child_Adult</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Handedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>sub-pixar155</td>\n",
       "      <td>26.00</td>\n",
       "      <td>Adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sub-pixar123</td>\n",
       "      <td>27.06</td>\n",
       "      <td>Adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sub-pixar124</td>\n",
       "      <td>33.44</td>\n",
       "      <td>Adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sub-pixar125</td>\n",
       "      <td>31.00</td>\n",
       "      <td>Adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sub-pixar126</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id    Age AgeGroup Child_Adult Gender Handedness\n",
       "154   sub-pixar155  26.00    Adult       adult      M          R\n",
       "122   sub-pixar123  27.06    Adult       adult      F          R\n",
       "123   sub-pixar124  33.44    Adult       adult      M          R\n",
       "124   sub-pixar125  31.00    Adult       adult      M          R\n",
       "125   sub-pixar126  19.00    Adult       adult      F          R"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2f80e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_difumo</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/jaizor/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">difumo_atlases</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_difumo\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/jaizor/nilearn_data/\u001b[0m\u001b[95mdifumo_atlases\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. SET UP ATLAS & CONNECTIVITY\n",
    "# -------------------------------\n",
    "\n",
    "# Atlas\n",
    "difumo = datasets.fetch_atlas_difumo(dimension=64, resolution_mm=2)\n",
    "\n",
    "# Masker \n",
    "masker = NiftiMapsMasker(\n",
    "    maps_img=difumo.maps,\n",
    "    standardize=\"zscore_sample\",     # Standardize BOLD time series (per region)\n",
    "    standardize_confounds=True,      # Standardize each confound regressor (mean=0, std=1)\n",
    "    memory=\"nilearn_cache\",\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Connectivity\n",
    "connectome_measure = ConnectivityMeasure(\n",
    "    kind=\"correlation\",        # Compute Pearson correlation between region time series\n",
    "    vectorize=True,            # Convert each subject's NxN matrix into a 1D feature vector                             \n",
    "    discard_diagonal=True      # Exclude the diagonal (self-connections), which are always 1.0 \n",
    "                               \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1e85a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 1/155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaizor/jaizor/xtra/miniconda3/envs/Xtra/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.\n",
      "  data_to_wrap = f(self, X, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 2/155\n",
      "Processing subject 3/155\n",
      "Processing subject 4/155\n",
      "Processing subject 5/155\n",
      "Processing subject 6/155\n",
      "Processing subject 7/155\n",
      "Processing subject 8/155\n",
      "Processing subject 9/155\n",
      "Processing subject 10/155\n",
      "Processing subject 11/155\n",
      "Processing subject 12/155\n",
      "Processing subject 13/155\n",
      "Processing subject 14/155\n",
      "Processing subject 15/155\n",
      "Processing subject 16/155\n",
      "Processing subject 17/155\n",
      "Processing subject 18/155\n",
      "Processing subject 19/155\n",
      "Processing subject 20/155\n",
      "Processing subject 21/155\n",
      "Processing subject 22/155\n",
      "Processing subject 23/155\n",
      "Processing subject 24/155\n",
      "Processing subject 25/155\n",
      "Processing subject 26/155\n",
      "Processing subject 27/155\n",
      "Processing subject 28/155\n",
      "Processing subject 29/155\n",
      "Processing subject 30/155\n",
      "Processing subject 31/155\n",
      "Processing subject 32/155\n",
      "Processing subject 33/155\n",
      "Processing subject 34/155\n",
      "Processing subject 35/155\n",
      "Processing subject 36/155\n",
      "Processing subject 37/155\n",
      "Processing subject 38/155\n",
      "Processing subject 39/155\n",
      "Processing subject 40/155\n",
      "Processing subject 41/155\n",
      "Processing subject 42/155\n",
      "Processing subject 43/155\n",
      "Processing subject 44/155\n",
      "Processing subject 45/155\n",
      "Processing subject 46/155\n",
      "Processing subject 47/155\n",
      "Processing subject 48/155\n",
      "Processing subject 49/155\n",
      "Processing subject 50/155\n",
      "Processing subject 51/155\n",
      "Processing subject 52/155\n",
      "Processing subject 53/155\n",
      "Processing subject 54/155\n",
      "Processing subject 55/155\n",
      "Processing subject 56/155\n",
      "Processing subject 57/155\n",
      "Processing subject 58/155\n",
      "Processing subject 59/155\n",
      "Processing subject 60/155\n",
      "Processing subject 61/155\n",
      "Processing subject 62/155\n",
      "Processing subject 63/155\n",
      "Processing subject 64/155\n",
      "Processing subject 65/155\n",
      "Processing subject 66/155\n",
      "Processing subject 67/155\n",
      "Processing subject 68/155\n",
      "Processing subject 69/155\n",
      "Processing subject 70/155\n",
      "Processing subject 71/155\n",
      "Processing subject 72/155\n",
      "Processing subject 73/155\n",
      "Processing subject 74/155\n",
      "Processing subject 75/155\n",
      "Processing subject 76/155\n",
      "Processing subject 77/155\n",
      "Processing subject 78/155\n",
      "Processing subject 79/155\n",
      "Processing subject 80/155\n",
      "Processing subject 81/155\n",
      "Processing subject 82/155\n",
      "Processing subject 83/155\n",
      "Processing subject 84/155\n",
      "Processing subject 85/155\n",
      "Processing subject 86/155\n",
      "Processing subject 87/155\n",
      "Processing subject 88/155\n",
      "Processing subject 89/155\n",
      "Processing subject 90/155\n",
      "Processing subject 91/155\n",
      "Processing subject 92/155\n",
      "Processing subject 93/155\n",
      "Processing subject 94/155\n",
      "Processing subject 95/155\n",
      "Processing subject 96/155\n",
      "Processing subject 97/155\n",
      "Processing subject 98/155\n",
      "Processing subject 99/155\n",
      "Processing subject 100/155\n",
      "Processing subject 101/155\n",
      "Processing subject 102/155\n",
      "Processing subject 103/155\n",
      "Processing subject 104/155\n",
      "Processing subject 105/155\n",
      "Processing subject 106/155\n",
      "Processing subject 107/155\n",
      "Processing subject 108/155\n",
      "Processing subject 109/155\n",
      "Processing subject 110/155\n",
      "Processing subject 111/155\n",
      "Processing subject 112/155\n",
      "Processing subject 113/155\n",
      "Processing subject 114/155\n",
      "Processing subject 115/155\n",
      "Processing subject 116/155\n",
      "Processing subject 117/155\n",
      "Processing subject 118/155\n",
      "Processing subject 119/155\n",
      "Processing subject 120/155\n",
      "Processing subject 121/155\n",
      "Processing subject 122/155\n",
      "Processing subject 123/155\n",
      "Processing subject 124/155\n",
      "Processing subject 125/155\n",
      "Processing subject 126/155\n",
      "Processing subject 127/155\n",
      "Processing subject 128/155\n",
      "Processing subject 129/155\n",
      "Processing subject 130/155\n",
      "Processing subject 131/155\n",
      "Processing subject 132/155\n",
      "Processing subject 133/155\n",
      "Processing subject 134/155\n",
      "Processing subject 135/155\n",
      "Processing subject 136/155\n",
      "Processing subject 137/155\n",
      "Processing subject 138/155\n",
      "Processing subject 139/155\n",
      "Processing subject 140/155\n",
      "Processing subject 141/155\n",
      "Processing subject 142/155\n",
      "Processing subject 143/155\n",
      "Processing subject 144/155\n",
      "Processing subject 145/155\n",
      "Processing subject 146/155\n",
      "Processing subject 147/155\n",
      "Processing subject 148/155\n",
      "Processing subject 149/155\n",
      "Processing subject 150/155\n",
      "Processing subject 151/155\n",
      "Processing subject 152/155\n",
      "Processing subject 153/155\n",
      "Processing subject 154/155\n",
      "Processing subject 155/155\n",
      "âœ… Feature matrix shape: (155, 2016)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. EXTRACT FEATURES FOR ALL SUBJECTS\n",
    "# -------------------------------\n",
    "\n",
    "all_features = []\n",
    "for i, (fmri, conf) in enumerate(zip(fmri_files, confound_files)):\n",
    "    print(f\"Processing subject {i+1}/{len(fmri_files)}\")\n",
    "    \n",
    "    # In fMRI, confounds are non-neural signals that can distort your brain activity estimates\n",
    "    confounds = pd.read_csv(conf, sep='\\t').values  # shape: (n_time, 15)\n",
    "    \n",
    "\n",
    "    # Extract denoised time series\n",
    "    time_series = masker.fit_transform(fmri, confounds=confounds)  # (n_time, 64)\n",
    "    \n",
    "    # Compute connectivity vector\n",
    "    conn_vec = connectome_measure.fit_transform([time_series])[0]  # (2016,)\n",
    "    all_features.append(conn_vec)\n",
    "\n",
    "\n",
    "# Convert to numpy array\n",
    "X_features = np.array(all_features)  # Shape: (155, 2016)\n",
    "print(\"âœ… Feature matrix shape:\", X_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8fb6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Features and phenotypes saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. SAVE OUTPUT\n",
    "# -------------------------------\n",
    "# Match subject IDs\n",
    "subject_ids = pheno['participant_id'].values\n",
    "assert len(subject_ids) == X_features.shape[0]\n",
    "\n",
    "# Save features + metadata\n",
    "np.savez_compressed(\n",
    "    'development_fmri_connectivity_features.npz',\n",
    "    X=X_features,\n",
    "    subject_ids=subject_ids,\n",
    "    labels=pheno[['Child_Adult', 'Age', 'Gender']].to_records(index=False)\n",
    ")\n",
    "\n",
    "# Also save phenotypic data separately (for easy loading)\n",
    "pheno.to_csv('development_fmri_pheno.csv', index=False)\n",
    "\n",
    "print(\"ðŸ’¾ Features and phenotypes saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
